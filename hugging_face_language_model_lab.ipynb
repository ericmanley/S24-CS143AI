{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C192SOmJS6lw",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hugging Face Language Model Lab\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ericmanley/S24-CS143AI/blob/main/hugging_face_language_model_lab.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Installing the Hugging Face `transformers` library\n",
    "\n",
    "You can install it with pip - this code should work running it locally or in Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### What is Hugging Face?\n",
    "\n",
    "Hugging Face is a private company\n",
    "* Founded in 2016 by French entrepreneurs Clément Delangue, Julien Chaumond, and Thomas Wolf\n",
    "* Based in New York City\n",
    "\n",
    "Provide popular free, open-source libraries for natural language processing (and other) tasks\n",
    "\n",
    "Host *hundreds of thousands of models* that you can use in your own programs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A first tranformers program: the sentiment analysis pipeline\n",
    "\n",
    "**Sentiment analysis** attempts to identify the overall feeling intended by the writer of some text\n",
    "\n",
    "The creators of this model **trained** it on lots of examples of text that were labeled as either *positive* or *negative*\n",
    "\n",
    "A **pipeline** is a series of steps for performing **inference**\n",
    "* tokenize and preprocess the input text (more on this later)\n",
    "* ask the model for a prediction\n",
    "* post-process model's result and turn it into something you can use\n",
    "\n",
    "\n",
    "<div>\n",
    "    <center>\n",
    "        <img src=\"images/full_nlp_pipeline.svg\" width=600px>\n",
    "    </center>\n",
    "</div>\n",
    "\n",
    "image source: https://huggingface.co/learn/nlp-course/chapter2/2?fw=pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We *are* specifying the kind of task: `sentiment-analysis`\n",
    "\n",
    "We *are not* asking for a specific model, so it picks one of many it has by default\n",
    "\n",
    "The first time you do this, it will have to download the model - this can take some time depending on your network connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43c18c67c16d4658a9a945c2f596e3fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d058711e06a545b1810e40feef11b32f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d26d1eb7edb4461b4ae019ed73f4fa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bcaa46170fb4f40b968fc3ee3590b1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'NEGATIVE', 'score': 0.9973069429397583}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "results = classifier(\"It would be really sad if I wasn't so happy\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test it out:** Try changing the input to get different labels/scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise: Specifying a model\n",
    "\n",
    "Now try asking for a specific model. \n",
    "\n",
    "Replace one line of code in your earlier example.\n",
    "\n",
    "You can find out more about this model by checking out its model card: https://huggingface.co/SamLowe/roberta-base-go_emotions\n",
    "\n",
    "What are some things you notice about this model that are different than the first one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = pipeline(\"sentiment-analysis\", model=\"SamLowe/roberta-base-go_emotions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise: Explore additional models\n",
    "\n",
    "Go to the Hugging Face models page: https://huggingface.co/models\n",
    "* click `Text Classification`\n",
    "* find another model that looks interesting to you and try it out\n",
    "* you might be able to find models for spam detection, fake news detection, topic classification, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What about sequence-to-sequence models?\n",
    "\n",
    "The transformers library has models for generating output sequences - long text as input and output\n",
    "* summarization\n",
    "* translation\n",
    "* question answering\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "/Users/000794593/Library/Python/3.10/lib/python/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# article copied from https://www.npr.org/2024/04/02/1242197022/biden-xi-jinping-call-china\n",
    "example_news_article = \"\"\"\n",
    "BEIJING and WASHINGTON, D.C. — President Biden and Chinese leader Xi Jinping held what a senior Biden administration official dubbed a \"check-in\" call on Tuesday, marking the first conversation between the leaders since their face-to-face meeting in California in November.\n",
    "The latest thorn in Taiwan-China tensions: pineapples\n",
    "World\n",
    "The latest thorn in Taiwan-China tensions: pineapples\n",
    "\n",
    "The call touched on everything from Taiwan to the situation on the Korean Peninsula, artificial intelligence and Russia's war in Ukraine.\n",
    "\n",
    "According to the Chinese readout, Xi told Biden strategic awareness \"must always be the first 'button' to be fastened\" in bilateral ties. The Chinese leader also elaborated his position on issues concerning Hong Kong, human rights and the South China Sea, the readout says.\n",
    "Taiwan's election was a vote for continuity, but adds uncertainty in ties with China\n",
    "World\n",
    "Taiwan's election was a vote for continuity, but adds uncertainty in ties with China\n",
    "\n",
    "The Chinese leader warned again that the \"Taiwan issue\" is an \"insurmountable red line\" in bilateral ties. Xi also urged Biden to \"translate\" his commitment of not supporting \"Taiwan independence\" into concrete actions, according to the readout.\n",
    "\n",
    "Biden, in the call, emphasized the importance of maintaining peace and stability across the Taiwan Strait and the rule of law and freedom of navigation in the South China Sea, according to a White House readout.\n",
    "\n",
    "The two leaders also discussed the global geopolitical situation. Biden, according to the White House, raised concerns over China's support for Russia's defense industrial base and its impact on European and transatlantic security. He also emphasized Washington's \"enduring commitment\" to the complete denuclearization of the Korean Peninsula.\n",
    "\n",
    "Tuesday's call was the first time Biden and Xi have talked since they met in northern California in November. There, they agreed on a range of steps to try to prevent increasingly fraught U.S.-China ties from slipping into conflict, including more frequent contact at the leader level, between militaries and beyond.\n",
    "\n",
    "Ahead of the call, a senior administration official told reporters the conversation would not represent a change in U.S. policy toward China, and competition remains a key feature.\n",
    "\n",
    "\"Intense competition requires intense diplomacy to manage tensions, address misperceptions and prevent unintended conflict. And this call is one way to do that,\" said the official, who spoke on condition of anonymity as he was not permitted to speak on the record.\n",
    "\n",
    "Biden raised perennial U.S. concerns about China's \"unfair trade policies and non-market economic practices,\" according to the White House readout — an issue that will be front and center when Treasury Secretary Janet Yellen visits China later this week.\n",
    "\n",
    "The president also reiterated to his Chinese counterpart that Washington will continue to \"take necessary actions to prevent advanced U.S. technologies from being used to undermine our national security, without unduly limiting trade and investment,\" the White House readout said.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': ' President Biden and Chinese leader Xi Jinping held what a senior Biden administration official dubbed a \"check-in\" call on Tuesday . The call touched on everything from Taiwan to the situation on the Korean Peninsula, artificial intelligence and Russia\\'s war in Ukraine . Tuesday\\'s call was the first time Biden and Xi have talked since they met in northern California in November .'}]\n"
     ]
    }
   ],
   "source": [
    "summary = summarizer(example_news_article)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What about chat bots?\n",
    "\n",
    "Chat bots need models that have been trained on conversational text. \n",
    "\n",
    "To get the next response in a conversational thread, you need to pass in the entire conversation up to that point.\n",
    "\n",
    "The `Conversation` object allows you to append messages to a thread to be used with the `conversational` pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, Conversation\n",
    "\n",
    "chatbot = pipeline(\"conversational\", model=\"facebook/blenderbot-400M-distill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "No chat template is defined for this tokenizer - using the default template for the BlenderbotTokenizerFast class. If the default is not appropriate for your model, please set `tokenizer.chat_template` to an appropriate template. See https://huggingface.co/docs/transformers/main/chat_templating for more information.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Computer science is a branch of mathematics that deals with the theory of computation.\n"
     ]
    }
   ],
   "source": [
    "# Conversation objects initialized with a string will treat it as a user message\n",
    "conversation = Conversation(\"What is computer science?\")\n",
    "conversation = chatbot(conversation)\n",
    "print(conversation.messages[-1][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Yes, it involves the study of algorithms and how they can be used to solve problems.\n"
     ]
    }
   ],
   "source": [
    "conversation.add_message({\"role\": \"user\", \"content\": \"Are you sure it is only a branch of mathematics? Doesn't it involve other things?\"})\n",
    "conversation = chatbot(conversation)\n",
    "print(conversation.messages[-1][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversation id: 2ef6049e-3a26-48fb-b264-35a1b8f5fd40\n",
      "user: What is computer science?\n",
      "assistant:  Computer science is a branch of mathematics that deals with the theory of computation.\n",
      "user: Are you sure it is only a branch of mathematics? Doesn't it involve other things?\n",
      "assistant:  Yes, it involves the study of algorithms and how they can be used to solve problems.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Here's what the whole conversation looks like\n",
    "print(conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': 'What is computer science?'},\n",
       " {'role': 'assistant',\n",
       "  'content': ' Computer science is a branch of mathematics that deals with the theory of computation.'},\n",
       " {'role': 'user',\n",
       "  'content': \"Are you sure it is only a branch of mathematics? Doesn't it involve other things?\"},\n",
       " {'role': 'assistant',\n",
       "  'content': ' Yes, it involves the study of algorithms and how they can be used to solve problems.'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here's some insight into how those messages are stored\n",
    "conversation.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise: Put this in a loop\n",
    "\n",
    "Write a loop that continually asks the user for input and displays a response from the chatbot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise: Try a larger model\n",
    "\n",
    "Try the `\"facebook/blenderbot-3B\"` model - it has 3 billion parameters instead of  400 million. It **might not work** - it could end up using too much memory on Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Experiment with the temperature\n",
    "\n",
    "You can set the `do_sample` and `temperature` parameters to affect how random the output is. Setting `do_sample=True` will allow it to use some randomness in generating output. The `temperature` affects how random it allows the output to be. Experiment with different temperature values and determine which value you're happiest with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " computer science is the study of the algorithms and computing systems and how they interact\n"
     ]
    }
   ],
   "source": [
    "conversation = Conversation(\"What is computer science?\")\n",
    "conversation = chatbot(conversation,do_sample=True,temperature=2.5)\n",
    "print(conversation.messages[-1][\"content\"])"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "authorship_tag": "ABX9TyOf2oi4GbgdvkO0orSdgZtQ",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
